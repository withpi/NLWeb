# This holds the environment variables needed for the webapp to run.
# It is recommended to set these variables in your shell profile (e.g., .bashrc, .zshrc) or in a secure environment.
# This script is for demonstration purposes only and should not be used in production.
# Make sure to replace the placeholder values with your actual keys and endpoints.


# Local Directory for file writes
#NLWEB_OUTPUT_DIR=/home/sites/data/nlweb

# NLWeb Logging profile (production, development, testing)
# This is used to set the logging level and other configurations in config/config_logging.py
NLWEB_LOGGING_PROFILE=production

# ANTHROPIC ENV VARIABLES
ANTHROPIC_API_KEY="<TODO>"

# AZURE ENV VARIABLES
# For instructions on obtaining the required Azure service keys, see ../docs/Azure.md
AZURE_VECTOR_SEARCH_ENDPOINT="https://TODO.search.windows.net" 
AZURE_VECTOR_SEARCH_API_KEY="<TODO>"

AZURE_OPENAI_ENDPOINT="https://TODO.openai.azure.com/"
AZURE_OPENAI_API_KEY="<TODO>"

# Cloudflare AutoRAG env variables
CLOUDFLARE_API_TOKEN="<TODO>"
CLOUDFLARE_RAG_ID_ENV="<TODO>"
CLOUDFLARE_ACCOUNT_ID="<TODO>"

# ELASTICSEARCH RETRIEVAL VARIABLES
ELASTICSEARCH_URL="http://localhost:9200"
ELASTICSEARCH_API_KEY="<TODO>"

GEMINI_API_KEY="<TODO>"

# Hugging Face Inference Providers env variables
HF_TOKEN="<TODO>"

# INCEPTION AI env variables
INCEPTION_ENDPOINT="https://api.inceptionlabs.ai/v1/chat/completions"
INCEPTION_API_KEY="<TODO>"

# MILVUS RETRIEVAL ENV VARIABLES
# Milvus has several deployment modes:
# - For dev, run Milvus Lite: Specify a local a file to persist data. No token needed.
MILVUS_ENDPOINT="../data/db/milvus.db"
# - For production, deploy a server and specify the URI and optionally "username:password" as token.
# MILVUS_ENDPOINT="http://localhost:19530"
# MILVUS_TOKEN="username:password" # If authentication is turned on, otherwise use empty string.
# - For fully managed Milvus (Zilliz Cloud): use Public Endpoint and API key of you Zilliz cluster.
# MILVUS_ENDPOINT="<copy_your_cluster_endpoint_here>"
# MILVUS_TOKEN="<copy_your_api_key_here>"

# OPEN AI ENV VARIABLES
OPENAI_ENDPOINT="https://api.openai.com/v1/chat/completions"
OPENAI_API_KEY="<TODO>"

# OPENSEARCH RETRIEVAL ENV VARIABLES
OPENSEARCH_ENDPOINT="<TODO>"
# Authentication credentials (username:password for basic auth, or API key)
OPENSEARCH_CREDENTIALS="<TODO>"

# QDRANT RETRIEVAL ENV VARIABLES
QDRANT_URL="http://localhost:6333"
QDRANT_API_KEY="<OPTIONAL>"

# POSTGRES CONNECTION STRING
POSTGRES_CONNECTION_STRING="postgresql://<HOST>:<PORT>/<DATABASE>?user=<USERNAME>&sslmode=require"
POSTGRES_PASSWORD="<PASSWORD>"

# SNOWFLAKE ENV VARIABLES
SNOWFLAKE_ACCOUNT_URL="<TODO>"
SNOWFLAKE_PAT="<TODO>"
# One of https://docs.snowflake.com/en/user-guide/snowflake-cortex/vector-embeddings#text-embedding-models
SNOWFLAKE_EMBEDDING_MODEL=snowflake-arctic-embed-l-v2.0
# For instructions on utilizing Snowflake services, see ../docs/Snowflake.md
# Fully qualified name of the cortex search service in your snowflake account
# For example TEMP.NLWEB.NLWEB_SAMPLE
# if you used snowflake.sql with --database TEMP --schema NLWEB
SNOWFLAKE_CORTEX_SEARCH_SERVICE=TODO